import sys
import time
import re
import threading
import traceback
import io
import ujson as json


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    
def safe_print(message):
    try:
        print(message, file=sys.stderr)
    except Exception:
        try:
            # Try to encode and decode manually
            safe_message = str(message).encode('utf-8', errors='replace').decode('utf-8')
            print(safe_message, file=sys.stderr)
        except Exception:
            try:
                # Last fallback: pure ASCII only, replace non-ASCII with ?
                safe_message = ''.join(c if ord(c) < 128 else '?' for c in str(message))
                print(safe_message, file=sys.stderr)
            except Exception:
                # Ultimate fallback: skip printing
                pass
            
def safe_thread_run(func, *args, **kwargs):
    try:
        func(*args, **kwargs)
    except Exception as e:
        safe_print(f"âš ï¸ Thread error: {str(e)}")


# Global lists to store products from different sources
skroutz_products = []
vendora_products = []
facebook_products = []
products_lock = threading.Lock()

def is_valid_product_link(link):
    """Validate if the link is a valid product link."""
    if not link:
        return False
    
    excluded_patterns = [
        "/user/items/boosts",
        "/items/create",
        "/user/items/",
        "/search",
        "/account",
        "/login",
        "/register",
        "/category/",
        "/cart",
        "/checkout"
    ]
    
    for pattern in excluded_patterns:
        if pattern in link:
            return False
    
    return (
        "/items/" in link and 
        not link.endswith("/items/") and 
        not link.endswith("/items") and
        len(link.split("/")[-1]) > 2  # Î‘Ï€Î¿ÎºÎ»ÎµÎ¯ÎµÎ¹ Ï€Î¿Î»Ï ÏƒÏÎ½Ï„Î¿Î¼Î± URLs
    )

def extract_price(text):
    """Î•ÎºÏ„ÎµÏ„Î±Î¼Î­Î½Î· ÎµÎ¾Î±Î³Ï‰Î³Î® Ï„Î¹Î¼ÏÎ½ Î³Î¹Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ® Î¼Î¿ÏÏ†Î¿Ï€Î¿Î¯Î·ÏƒÎ·."""
    if not text:
        return None
    
    # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
    text = text.strip()
    
    # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· ÏƒÏ…Î¼Î²ÏŒÎ»Î¿Ï… Î½Î¿Î¼Î¯ÏƒÎ¼Î±Ï„Î¿Ï‚
    text = text.replace('â‚¬', '').replace('ÎµÏ…ÏÏ', '').strip()
    
    # Î“Î¹Î± Ï„Î·Î½ ÎµÎ»Î»Î·Î½Î¹ÎºÎ® Î¼Î¿ÏÏ†Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÏŒÏ€Î¿Ï… Î· Ï„ÎµÎ»ÎµÎ¯Î± ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î¹ÎºÏŒ Ï‡Î¹Î»Î¹Î¬Î´Ï‰Î½
    if '.' in text and ',' not in text:
        # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Ï„ÎµÎ»ÎµÎ¹ÏÎ½ (Î´Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Ï‡Î¹Î»Î¹Î¬Î´Ï‰Î½)
        text = text.replace('.', '')
    elif '.' in text and ',' in text:
        # Î ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· 1.234,56
        if text.rindex('.') < text.rindex(','):
            text = text.replace('.', '')
            text = text.replace(',', '.')
        # Î ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· 1,234.56
        else:
            text = text.replace(',', '')
    elif ',' in text:
        # Î‘Î½Ï„Î¹ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· ÎºÏŒÎ¼Î¼Î±Ï„Î¿Ï‚ Î¼Îµ Ï„ÎµÎ»ÎµÎ¯Î± Î³Î¹Î± Î´ÎµÎºÎ±Î´Î¹ÎºÎ¬
        text = text.replace(',', '.')
    
    try:
        return float(text)
    except (ValueError, TypeError): 
        return None


def search_skroutz(search_term, min_price, max_price):
    global skroutz_products
    skroutz_products = []  # Reset for each search
    
    options = webdriver.FirefoxOptions()
    options.add_argument('--headless')
    options.add_argument('--window-size=1920,1080')
    driver = webdriver.Firefox(options=options)
    
    # ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ timeout Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ ÏƒÎµÎ»Î¯Î´Î±Ï‚
    driver.set_page_load_timeout(2)
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Ï‰Î½ Î±Î½Î±Î¼Î¿Î½Î®Ï‚ Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ timeouts
    short_wait = WebDriverWait(driver, 1)   # Î£ÏÎ½Ï„Î¿Î¼Î· Î±Î½Î±Î¼Î¿Î½Î®
    wait = WebDriverWait(driver, 1)        # ÎšÎ±Î½Î¿Î½Î¹ÎºÎ® Î±Î½Î±Î¼Î¿Î½Î®
    
    try:
        url = f"https://www.skroutz.gr/skoop?keyphrase={search_term.replace(' ', '+')}"        
        # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï„Î·Ï‚ ÏƒÎµÎ»Î¯Î´Î±Ï‚
        driver.get(url)
        
        # Î ÎµÏÎ¯Î¼ÎµÎ½Îµ Î³Î¹Î± Î­Î½Î± Î²Î±ÏƒÎ¹ÎºÏŒ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿ Ï€Î¿Ï… Î´ÎµÎ¯Ï‡Î½ÎµÎ¹ ÏŒÏ„Î¹ Î· ÏƒÎµÎ»Î¯Î´Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎµ
        try:
            # Î ÎµÏÎ¯Î¼ÎµÎ½Îµ Î³Î¹Î± Î¿Ï€Î¿Î¹Î¿Î´Î®Ï€Î¿Ï„Îµ Î±Ï€ÏŒ Î±Ï…Ï„Î¬ Ï„Î± ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± - ÏŒÏ€Î¿Î¹Î¿ Ï†Î¿ÏÏ„ÏÏƒÎµÎ¹ Ï€ÏÏÏ„Î¿
            page_loaded = wait.until(
                EC.any_of(
                    EC.presence_of_element_located((By.CSS_SELECTOR, ".sku-card, .c2c-item-card, .card, article")),
                    EC.presence_of_element_located((By.TAG_NAME, "footer")),
                    EC.presence_of_element_located((By.CSS_SELECTOR, "div[class*='product']"))
                )
            )
        except:
            safe_print("Basic page load detection timed out, continuing anyway")
        
        # Î£Ï„Î±Î¼Î¬Ï„Î·ÏƒÎµ ÎµÏ€Î¹Ï€Î»Î­Î¿Î½ Î±Î¹Ï„Î®Î¼Î±Ï„Î± Î´Î¹ÎºÏ„ÏÎ¿Ï… Î¼ÎµÏ„Î¬ Ï„Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ· Î²Î±ÏƒÎ¹ÎºÏÎ½ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Ï‰Î½
        driver.execute_script("""
            window.stop();
            // Î‘Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¬Î»Î»Ï‰Î½ Î±Î¹Ï„Î·Î¼Î¬Ï„Ï‰Î½ Ï€Î¿Ï… Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬
            const originalFetch = window.fetch;
            window.fetch = function() {
                const url = arguments[0];
                if (url.includes('analytics') || url.includes('tracking') || url.includes('ads')) {
                    console.log('Blocked fetch:', url);
                    return new Promise(() => {});
                }
                return originalFetch.apply(this, arguments);
            }
        """)
        
        # Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ cookie banner - Î¼Îµ ÏƒÏÎ½Ï„Î¿Î¼Î¿ timeout
        try:
            cookie_selectors = [
                "//button[contains(text(), 'Î‘Ï€Î¿Î´Î¿Ï‡Î®')]",
                "//button[contains(@class, 'accept')]",
                "//*[contains(@class, 'cookie-accept')]",
                "//button[text()='Î‘Ï€Î¿Î´Î¿Ï‡Î® ÏŒÎ»Ï‰Î½']"
            ]
            
            for selector in cookie_selectors:
                try:
                    cookie_button = short_wait.until(EC.element_to_be_clickable((By.XPATH, selector)))
                    cookie_button.click()
                    safe_print("Cookie accepted", file=sys.stderr)
                    break
                except:
                    continue
        except:
            safe_print("No cookie banner or couldn't accept", file=sys.stderr)
        
        # Î“ÏÎ®Î³Î¿ÏÎ¿ scroll Î³Î¹Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ· Î´Ï…Î½Î±Î¼Î¹ÎºÎ¿Ï Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Î¿Ï…
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.3);")
        time.sleep(0.05)  # ÎœÎ¹ÎºÏÏŒÏ„ÎµÏÎ¿Ï‚ Ï‡ÏÏŒÎ½Î¿Ï‚ Î±Î½Î±Î¼Î¿Î½Î®Ï‚
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.6);")
        time.sleep(0.05)
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(0.05)
        
        # Î’ÎµÎ»Ï„Î¹Ï‰Î¼Î­Î½Î¿Î¹ ÎµÏ€Î¹Î»Î¿Î³ÎµÎ¯Ï‚ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ Î³Î¹Î± Skroutz Skoop
        product_selectors = [
            "//li[contains(@class, 'sku-card')]",  # Î’Î±ÏƒÎ¹ÎºÏŒÏ‚ ÎµÏ€Î¹Î»Î¿Î³Î­Î±Ï‚ Î±Ï€ÏŒ Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ·
            "//li[contains(@class, 'c2c-item-card')]",  # Î†Î»Î»Î¿Ï‚ ÏƒÏ…Î½Î·Î¸Î¹ÏƒÎ¼Î­Î½Î¿Ï‚
            "//div[contains(@class, 'card')]",
            "//div[contains(@class, 'product-card')]",
            "//article[contains(@class, 'card')]",
            "//article[contains(@class, 'skoop-item')]"
        ]
        
        products = []
        for selector in product_selectors:
            try:
                found_products = driver.find_elements(By.XPATH, selector)
                if found_products:
                    products = found_products
                    break
            except Exception as e:
                continue
        
        # Î•Î½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ® Î¼Î­Î¸Î¿Î´Î¿Ï‚ Î¼Îµ JavaScript Î±Î½ Î¿Î¹ ÎµÏ€Î¹Î»Î¿Î³ÎµÎ¯Ï‚ Î´ÎµÎ½ Î²ÏÎ®ÎºÎ±Î½ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î±
        if not products or len(products) <=1 :
            # Î•Î½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ® Ï€ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ· Î¼Îµ JavaScript Î³Î¹Î± ÎµÎ¾Î±Î³Ï‰Î³Î® Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½
            products_data = driver.execute_script("""
                return Array.from(document.querySelectorAll('li.sku-card, li.c2c-item-card, div.card, article.card')).map(card => {
                    try {
                        // Î¤Î¯Ï„Î»Î¿Ï‚
                        let title = '';
                        const titleEl = card.querySelector('h2, h3, a.js-sku-link, .sku-name, .product-name');
                        if (titleEl) title = titleEl.textContent.trim();
                        
                        // Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿Ï‚
                        let link = '';
                        const linkEl = card.querySelector('a.js-sku-link, a[href*="/skoop/items/"]');
                        if (linkEl) link = linkEl.href;
                        
                        // Î¤Î¹Î¼Î®
                        let price = '';
                        const priceEl = card.querySelector('.price, [class*="price"], [class*="amount"]');
                        if (priceEl) price = priceEl.textContent.trim();
                        
                        // Î•Î¹ÎºÏŒÎ½Î±
                        let image = null;
                        // Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î½Î± Î²ÏÎ¿ÏÎ¼Îµ ÎµÎ¹ÎºÏŒÎ½Î± Î¼Î­ÏƒÎ± ÏƒÏ„Î·Î½ ÎºÎ¬ÏÏ„Î±
                        const imgContainer = card.querySelector('.image-container, .sku-card-pic, [class*="image"]');
                        const img = imgContainer ? imgContainer.querySelector('img') : card.querySelector('img');
                        
                        if (img) {
                            image = img.src || img.getAttribute('data-src');
                        }
                        
                        return { title, link, price, image };
                    } catch(e) {
                        return null;
                    }
                }).filter(item => item && item.title && item.link);
            """)
            
            
            # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï„Ï‰Î½ JavaScript Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ ÏƒÎµ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î±
            if products_data and len(products_data) > 0:
                for product_data in products_data:
                    try:
                        title = product_data.get('title', '').strip()
                        price_text = product_data.get('price', '').strip()
                        link = product_data.get('link', '')
                        image_url = product_data.get('image')
                        
                        if not title or not link or not is_valid_product_link(link):
                            continue
                        
                        # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· debug logging Î³Î¹Î± Î­Î»ÎµÎ³Ï‡Î¿
                        safe_print(f"Debug - Î¤Î¹Î¼Î® ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…: {price_text}")
                        
                        # Î•Î¾Î±Î³Ï‰Î³Î® Ï„Î¹Î¼Î®Ï‚
                        price = extract_price(price_text)
                        
                        # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· debug logging
                        safe_print(f"Debug - Î•Î¾Î±Î³Î¼Î­Î½Î· Ï„Î¹Î¼Î®: {price}, Î¤ÏÏ€Î¿Ï‚: {type(price)}")
                        safe_print(f"Debug - min_price: {min_price}, Î¤ÏÏ€Î¿Ï‚: {type(min_price)}")
                        safe_print(f"Debug - max_price: {max_price}, Î¤ÏÏ€Î¿Ï‚: {type(max_price)}")
                        
                        # Î’ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ ÏŒÎ»ÎµÏ‚ Î¿Î¹ Ï„Î¹Î¼Î­Ï‚ ÎµÎ¯Î½Î±Î¹ Î±ÏÎ¹Î¸Î¼Î¿Î¯
                        if price is not None:
                            price = float(price)
                            min_price = float(min_price)
                            max_price = float(max_price)
                            
                            if price is not None and min_price <= price <= max_price:

                                # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î¿
                                is_duplicate = any(link == existing[2] for existing in skroutz_products)
                                if not is_duplicate:
                                    with products_lock:
                                        skroutz_products.append((title, price, link, image_url))
                    except Exception as e:
                        safe_print(f"Î£Ï†Î¬Î»Î¼Î±: {e}")  # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÏƒÏ†Î¬Î»Î¼Î±Ï„Î¿Ï‚ Î±Î½Ï„Î¯ Î³Î¹Î± ÏƒÎ¹Ï‰Ï€Î·ÏÎ® ÏƒÏ…Î½Î­Ï‡Î¹ÏƒÎ·
                        continue
            
            # Î”Î¿ÎºÎ¹Î¼Î® Î±Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ ÎµÎ¾Î±Î³Ï‰Î³Î®Ï‚ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½ Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ· JSON
            if not skroutz_products or len(skroutz_products) < 3:
                # Î•Î¾Î±Î³Ï‰Î³Î® ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½
                all_images = driver.execute_script("""
                    return Array.from(document.querySelectorAll('img')).map(img => {
                        const rect = img.getBoundingClientRect();
                        const parent = img.closest('li.sku-card, li.c2c-item-card, div.card, article.card');
                        
                        return {
                            src: img.src,
                            dataSrc: img.getAttribute('data-src'),
                            width: img.width,
                            height: img.height,
                            alt: img.alt,
                            inViewport: (
                                rect.top >= 0 &&
                                rect.left >= 0 &&
                                rect.bottom <= window.innerHeight &&
                                rect.right <= window.innerWidth
                            ),
                            hasParentCard: parent !== null,
                            parentId: parent ? parent.id : null
                        };
                    }).filter(img => (img.src && img.src.includes('scdn.gr') && img.width > 50 && img.height > 50));
                """)
                
                
                # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î½Î± ÏƒÏ…Î½Î´Î­ÏƒÎ¿Ï…Î¼Îµ Ï„Î¹Ï‚ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚ Î¼Îµ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î±
                if all_images and len(all_images) > 0:
                    # Î•Î¾Î±Î³Ï‰Î³Î® Î¼ÏŒÎ½Î¿ Ï„Ï‰Î½ ÏƒÏ…Î½Î´Î­ÏƒÎ¼Ï‰Î½ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½
                    product_links = driver.execute_script("""
                        return Array.from(document.querySelectorAll('a.js-sku-link, a[href*="/skoop/items/"]')).map(a => {
                            return {
                                href: a.href,
                                title: a.textContent.trim() || a.getAttribute('title'),
                                parentCard: a.closest('li.sku-card, li.c2c-item-card, div.card, article.card'),
                                parentId: a.closest('li.sku-card, li.c2c-item-card, div.card, article.card') ? 
                                          a.closest('li.sku-card, li.c2c-item-card, div.card, article.card').id : null,
                                nearestPriceText: (() => {
                                    // Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î½Î± Î²ÏÎ¿ÏÎ¼Îµ Ï„Î·Î½ Ï„Î¹Î¼Î® ÎºÎ¿Î½Ï„Î¬ ÏƒÏ„Î¿Î½ ÏƒÏÎ½Î´ÎµÏƒÎ¼Î¿
                                    const priceEl = a.parentElement.querySelector('[class*="price"], [class*="amount"]') ||
                                                  a.closest('li, div, article').querySelector('[class*="price"], [class*="amount"]');
                                    return priceEl ? priceEl.textContent.trim() : '';
                                })()
                            };
                        }).filter(link => link.href && link.href.includes('/skoop/items/') && link.title);
                    """)
                    
                    
                    # Î“Î¹Î± ÎºÎ¬Î¸Îµ ÏƒÏÎ½Î´ÎµÏƒÎ¼Î¿ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î¿Ï‚, Ï€ÏÎ¿ÏƒÏ€Î¬Î¸Î·ÏƒÎµ Î½Î± Î²ÏÎµÎ¹Ï‚ Î¼Î¹Î± Î±Î½Ï„Î¯ÏƒÏ„Î¿Î¹Ï‡Î· ÎµÎ¹ÎºÏŒÎ½Î±
                    for product_link in product_links:
                        try:
                            link = product_link.get('href', '')
                            title = product_link.get('title', '')
                            price_text = product_link.get('nearestPriceText', '')
                            parent_id = product_link.get('parentId')
                            
                            if not is_valid_product_link(link):
                                continue
                                
                            # Î•ÎºÏ‡ÏÏÎ·ÏƒÎ· ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ parent ID Î® ÎµÎ³Î³ÏÏ„Î·Ï„Î±
                            image_url = None
                            
                            # Î‘Î½ Î­Ï‡Î¿Ï…Î¼Îµ parent ID, ÎºÎ¬Î½Îµ Î±Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ·
                            if parent_id:
                                for img in all_images:
                                    if img.get('parentId') == parent_id:
                                        image_url = img.get('src') or img.get('dataSrc')
                                        break
                            
                            # Î‘Î½ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÎµÎ¹ÎºÏŒÎ½Î±, Ï€Î¬ÏÎµ Î¼Î¹Î± Î±Ï€ÏŒ Ï„Î¹Ï‚ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚ Ï€Î¿Ï… Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î±
                            if not image_url and all_images:
                                # Î”Î¿ÎºÎ¹Î¼Î® Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ ID Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î¿Ï‚
                                item_id_match = re.search(r'/items/(\d+)', link)
                                if item_id_match:
                                    item_id = item_id_match.group(1)
                                    for img in all_images:
                                        img_src = img.get('src', '')
                                        if item_id in img_src:
                                            image_url = img_src
                                            break
                            
                            # Î¤ÎµÎ»ÎµÏ…Ï„Î±Î¯Î± Ï€ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î±: Ï€Î¬ÏÎµ Î¿Ï€Î¿Î¹Î±Î´Î®Ï€Î¿Ï„Îµ ÎµÎ¹ÎºÏŒÎ½Î± Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î¿Ï‚ Ï€Î¿Ï… Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯
                            if not image_url and all_images:
                                # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Î· ÎµÎ¹ÎºÏŒÎ½Î± Î­Ï‡ÎµÎ¹ Î®Î´Î· Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯
                                used_images = [item[3] for item in skroutz_products if item[3]]
                                for img in all_images:
                                    img_src = img.get('src', '')
                                    if img_src not in used_images and 'thumbnail' in img_src:
                                        image_url = img_src
                                        break
                            
                            price = extract_price(price_text)
                            if price is not None and min_price <= price <= max_price:
                                is_duplicate = any(link == existing[2] for existing in skroutz_products)
                                if not is_duplicate:
                                    with products_lock:
                                        skroutz_products.append((title, price, link, image_url))
                        except Exception as e:
                            safe_print("Error processing product link")
        
        # Î‘Î½ Î­Ï‡Î¿Ï…Î¼Îµ product cards, ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î¼Îµ Ï„Î·Î½ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ® ÏÎ¿Î®
        else:
            for product in products:
                try:
                    # Î’ÎµÎ»Ï„Î¹Ï‰Î¼Î­Î½Î· ÎµÎ¾Î±Î³Ï‰Î³Î® Ï„Î¯Ï„Î»Î¿Ï…
                    title_selectors = [
                        ".//h2",
                        ".//h3",
                        ".//*[contains(@class, 'title')]",
                        ".//*[contains(@class, 'name')]",
                        ".//a[contains(@class, 'js-sku-link')]",
                        ".//a[contains(@href, '/skoop/items/')]"
                    ]
                    
                    title = None
                    for title_selector in title_selectors:
                        try:
                            title_element = product.find_element(By.XPATH, title_selector)
                            title = title_element.text.strip()
                            if title:
                                break
                        except:
                            continue
                    
                    if not title:
                        # Fallback: try getting text from the entire product card
                        title = product.text.split('\n')[0].strip()
                    
                    # Î’ÎµÎ»Ï„Î¹Ï‰Î¼Î­Î½Î· ÎµÎ¾Î±Î³Ï‰Î³Î® Ï„Î¹Î¼Î®Ï‚
                    price_selectors = [
                        ".//span[contains(text(),'â‚¬')]",
                        ".//*[contains(@class, 'price')]",
                        ".//*[contains(text(),'â‚¬')]",
                        ".//*[contains(@class, 'amount')]"
                    ]
                    
                    price_text = None
                    for price_selector in price_selectors:
                        try:
                            price_element = product.find_element(By.XPATH, price_selector)
                            price_text = price_element.text.strip()
                            if price_text:
                                break
                        except:
                            continue
                    
                    # Î•Î¾Î±Î³Ï‰Î³Î® ÏƒÏ…Î½Î´Î­ÏƒÎ¼Î¿Ï…
                    link_selectors = [
                        ".//a[contains(@class, 'js-sku-link')]",
                        ".//a[contains(@href, '/skoop/items/')]",
                        ".//a[contains(@href, '/products/')]",
                        ".//a"
                    ]
                    
                    link = None
                    for link_selector in link_selectors:
                        try:
                            link_element = product.find_element(By.XPATH, link_selector)
                            link = link_element.get_attribute("href")
                            if link and is_valid_product_link(link):
                                break
                        except:
                            continue
                    
                    # Î’ÎµÎ»Ï„Î¹Ï‰Î¼Î­Î½Î· ÎµÎ¾Î±Î³Ï‰Î³Î® ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ JSON Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚
                    image_url = None
                    image_selectors = [
                        ".//div[contains(@class, 'image-container')]//img",  # Î’Î±ÏƒÎ¹ÎºÏŒÏ‚ ÎµÏ€Î¹Î»Î¿Î³Î­Î±Ï‚ Î±Ï€ÏŒ Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ·
                        ".//div[contains(@class, 'sku-card-pic')]//img",     # Î’Î±ÏƒÎ¹ÎºÏŒÏ‚ ÎµÏ€Î¹Î»Î¿Î³Î­Î±Ï‚ Î±Ï€ÏŒ Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ·
                        ".//img",                                            # ÎŒÏ€Î¿Î¹Î± ÎµÎ¹ÎºÏŒÎ½Î± Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
                        ".//*[contains(@class, 'image')]//img"
                    ]

                    for image_selector in image_selectors:
                        try:
                            image_elements = product.find_elements(By.XPATH, image_selector)
                            for image_element in image_elements:
                                # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± Î¼Î¿Ï„Î¯Î²Î± ÎµÎ¹ÎºÏŒÎ½Ï‰Î½ Skroutz
                                src = image_element.get_attribute("src")
                                if src and ('scdn.gr' in src or 'skroutz.gr' in src) and not src.endswith('.png'):
                                    # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Ï„Ï‰Î½ favicon ÎºÎ±Î¹ Î¬Î»Î»Ï‰Î½ Î¼Î¹ÎºÏÏÎ½ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½
                                    width = image_element.get_attribute("width")
                                    height = image_element.get_attribute("height")
                                    try:
                                        if width and height and int(width) > 50 and int(height) > 50:
                                            image_url = src
                                            break
                                    except:
                                        # Î‘Î½ Î´ÎµÎ½ Î¼Ï€Î¿ÏÎ¿ÏÎ¼Îµ Î½Î± Î¼ÎµÏ„Î±Ï„ÏÎ­ÏˆÎ¿Ï…Î¼Îµ Ï„Î¹Ï‚ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚, Î´ÎµÏ‡ÏŒÎ¼Î±ÏƒÏ„Îµ Ï„Î·Î½ ÎµÎ¹ÎºÏŒÎ½Î± Î±Î½ Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ 'thumbnail'
                                        if 'thumbnail' in src:
                                            image_url = src
                                            break
                                # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± data-src
                                data_src = image_element.get_attribute("data-src")
                                if not image_url and data_src and ('scdn.gr' in data_src or 'skroutz.gr' in data_src):
                                    image_url = data_src
                                    break
                            if image_url:
                                break
                        except Exception as e:
                            continue
                    
                    # Î‘Î½ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÎµÎ¹ÎºÏŒÎ½Î±, Î´Î¿ÎºÎ¹Î¼Î® Î½Î± ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î±ÏƒÏ„ÎµÎ¯ Ï„Î¿ URL ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ Î±Ï€ÏŒ Ï„Î¿ ID Ï„Î¿Ï… Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î¿Ï‚
                    if not image_url and link:
                        try:
                            item_id_match = re.search(r'/items/(\d+)', link)
                            if item_id_match:
                                item_id = item_id_match.group(1)
                                # Î¤Î¿ Î¼Î¿Ï„Î¯Î²Î¿ Ï„Ï‰Î½ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½ Skroutz Î±Ï€ÏŒ Ï„Î¿ JSON Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚
                                domain = 'a.scdn.gr' if int(item_id) % 3 == 0 else ('b.scdn.gr' if int(item_id) % 3 == 1 else 'c.scdn.gr')
                                image_url = f"https://{domain}/ds/c2c/item_images/h-{item_id}/thumbnail_recent.jpeg"
                        except Exception as e:
                            safe_print(" URL construction error")
                    
                    # Î•Î¾Î±Î³Ï‰Î³Î® Ï„Î¹Î¼Î®Ï‚ ÎºÎ±Î¹ Ï€ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
                    price = extract_price(price_text)
                    
                    if price is not None and title and link:
                        if price is not None and min_price <= price <= max_price:

                            with products_lock:
                                skroutz_products.append((title, price, link, image_url))
                
                except Exception as e:
                    safe_print("Skroutz product error")
    
    except Exception as e:
        safe_print("Skroutz search error")
    
    finally:
        driver.quit()


def search_facebook(search_term, min_price, max_price, location="athens", max_pages=5):
    """
    Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· ÏƒÏ„Î¿ Facebook Marketplace Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿Î½ ÏŒÏÎ¿ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚ ÎºÎ±Î¹ ÎµÏÏÎ¿Ï‚ Ï„Î¹Î¼Î®Ï‚.
    """
    global facebook_products
    facebook_products = []  # Reset Î³Î¹Î± ÎºÎ¬Î¸Îµ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·
    
    # Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ Firefox
    options = webdriver.FirefoxOptions()
    options.add_argument('--headless')  # Î£Ï‡ÏŒÎ»Î¹Î¿ Î³Î¹Î± ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Î¿Ï… browser ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·
    options.add_argument('--disable-gpu')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.set_preference("general.useragent.override", "Mozilla/5.0 (Windows NT 10.0; Win64; x64)")
    options.page_load_strategy = 'eager'  # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î¼ÏŒÎ½Î¿ Ï„Î¿Ï… Î²Î±ÏƒÎ¹ÎºÎ¿Ï Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Î¿Ï…
    
    # Î•ÎºÎºÎ¯Î½Î·ÏƒÎ· WebDriver
    driver = webdriver.Firefox(options=options)
    wait = WebDriverWait(driver, 5.0)
    
    try:
        # Î†Î½Î¿Î¹Î³Î¼Î± Ï„Î¿Ï… Facebook Marketplace Î¼Îµ Ï„Î¿Î½ ÏŒÏÎ¿ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚
        base_url = f"https://www.facebook.com/marketplace/athens/search?query={search_term.replace(' ', '%20')}"
        safe_print(f"ğŸ”„ Î†Î½Î¿Î¹Î³Î¼Î± Ï„Î¿Ï… Facebook Marketplace Î¼Îµ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·: {search_term}...")
        driver.get(base_url)
        
        # Î ÎµÏÎ¹Î¼Î­Î½Î¿Ï…Î¼Îµ Î»Î¯Î³Î¿ Î½Î± Ï†Î¿ÏÏ„ÏÏƒÎµÎ¹ Î· ÏƒÎµÎ»Î¯Î´Î±
        time.sleep(5)
        
        # ÎšÎ»ÎµÎ¯ÏƒÎ¹Î¼Î¿ Ï„Î¿Ï… Ï€Î±ÏÎ±Î¸ÏÏÎ¿Ï… ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚/cookie Î±Î½ ÎµÎ¼Ï†Î±Î½Î¹ÏƒÏ„ÎµÎ¯
        try:
            close_buttons = driver.find_elements(By.XPATH, "//div[@aria-label='Close'] | //button[contains(@data-testid, 'cookie-policy')] | //button[contains(text(), 'Decline') or contains(text(), 'Î‘Ï€ÏŒÏÏÎ¹ÏˆÎ·')]")
            if close_buttons:
                close_buttons[0].click()
                safe_print("âœ… ÎˆÎºÎ»ÎµÎ¹ÏƒÎµ Ï„Î¿ Ï€Î±ÏÎ¬Î¸Ï…ÏÎ¿ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚/cookie")
                time.sleep(2)
        except Exception as e:
            safe_print(f"âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï€Î±ÏÎ¬Î¸Ï…ÏÎ¿ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ Î® Ï€ÏÎ¿Î­ÎºÏ…ÏˆÎµ ÏƒÏ†Î¬Î»Î¼Î±: {str(e)}")
        
        # Î“Î¹Î± ÎºÎ¬Î¸Îµ ÏƒÎµÎ»Î¯Î´Î± Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ (simulating pagination through scrolling)
        for page in range(1, max_pages + 1):
            safe_print(f"ğŸ“ƒ Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÏƒÎµÎ»Î¯Î´Î±Ï‚ {page}...")
            
            # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÎºÏÎ´Î¹ÎºÎ± Î³Î¹Î± ÏƒÏ„Î±Î´Î¹Î±ÎºÏŒ scroll
            try:
                last_height = driver.execute_script("return document.body.scrollHeight")
                scroll_pause_time = 1.0
                scroll_attempts = 3
                max_scroll_attempts = 3  # ÎœÎ­Î³Î¹ÏƒÏ„Î¿Ï‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¹ÏÎ½ scroll Î±Î½Î¬ "ÏƒÎµÎ»Î¯Î´Î±"
                
                while scroll_attempts < max_scroll_attempts:
                    # Scroll Ï€ÏÎ¿Ï‚ Ï„Î± ÎºÎ¬Ï„Ï‰
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(scroll_pause_time)
                    
                    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î½Î­Î¿Ï… ÏÏˆÎ¿Ï…Ï‚ scroll
                    new_height = driver.execute_script("return document.body.scrollHeight")
                    
                    # Î‘Î½ Î´ÎµÎ½ Î±Î»Î»Î¬Î¾ÎµÎ¹ Ï„Î¿ ÏÏˆÎ¿Ï‚, Î­Ï‡Î¿Ï…Î¼Îµ Ï†Ï„Î¬ÏƒÎµÎ¹ ÏƒÏ„Î¿ Ï„Î­Î»Î¿Ï‚
                    if new_height == last_height:
                        break
                    
                    last_height = new_height
                    scroll_attempts += 1
                    safe_print(f"  â†“ Scroll {scroll_attempts}/{max_scroll_attempts}")
            except Exception as e:
                safe_print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î¿ scroll: {str(e)}")
            
            # Î•ÏÏÎµÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Î±Î³Î³ÎµÎ»Î¹ÏÎ½ ÏƒÏ„Î·Î½ Ï„ÏÎ­Ï‡Î¿Ï…ÏƒÎ± "ÏƒÎµÎ»Î¯Î´Î±"
            try:
                # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± ÎµÏÏÎµÏƒÎ·Ï‚ Î¼Îµ Î´Î¹Î¬Ï†Î¿ÏÎ¿Ï…Ï‚ CSS selectors Ï€Î¿Ï… Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î¿ Facebook
                listings = driver.find_elements(By.CSS_SELECTOR, "div[role='feed'] > div")
                
                if not listings:
                    listings = driver.find_elements(By.CSS_SELECTOR, "div[role='main'] div[data-testid='marketplace_feed_item']")
                
                if not listings:
                    listings = driver.find_elements(By.CSS_SELECTOR, "div.x1iorvi4")  # Î Î¹Î¸Î±Î½ÏŒÏ‚ ÎµÏ€Î¹Î»Î¿Î³Î­Î±Ï‚ Facebook
                
                safe_print(f"  ğŸ” Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(listings)} Î±Î³Î³ÎµÎ»Î¯ÎµÏ‚ Î³Î¹Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±")
                
                for listing in listings:
                    try:
                        # Î•Î¾Î±Î³Ï‰Î³Î® Ï„Î¯Ï„Î»Î¿Ï…
                        title_element = listing.find_elements(By.CSS_SELECTOR, "span.x1lliihq, div.x3ct3a4 > span")
                        
                        if not title_element:
                            continue
                            
                        title = title_element[0].text.strip()
                        
                        # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿Î½ ÏŒÏÎ¿ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚ ÏƒÏ„Î¿Î½ Ï„Î¯Ï„Î»Î¿ Î±Î½ ÎµÎ¯Î½Î±Î¹ Î±Î½Î±Î³ÎºÎ±Î¯Î¿
                        if search_term and search_term.lower() not in title.lower():
                            continue
                        
                        # Î•Î¾Î±Î³Ï‰Î³Î® Ï„Î¹Î¼Î®Ï‚
                        try:
                            price_element = listing.find_elements(By.CSS_SELECTOR, "span.x193iq5w, span[data-testid='marketplace_feed_item_price']")
                            if not price_element:
                                price_element = listing.find_elements(By.XPATH, ".//span[contains(@class, 'x193iq5w')]")
                            
                            if not price_element:
                                continue

                            price_text = price_element[0].text.strip()
                            price = extract_price(price_text)

                            if price is None:
                                continue
                                
                            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Ï„Î¹Î¼Î®Ï‚ ÏƒÏ„Î¿ ÎµÏÏÎ¿Ï‚ Ï€Î¿Ï… Î¶Î·Ï„Î®Î¸Î·ÎºÎµ
                            if not (min_price <= price <= max_price):
                                continue
                                
                        except Exception as e:
                            safe_print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÎµÎ¾Î±Î³Ï‰Î³Î®Ï‚ Ï„Î¹Î¼Î®Ï‚: {str(e)}")
                            continue
                        
                        # Î•Î¾Î±Î³Ï‰Î³Î® ÏƒÏ…Î½Î´Î­ÏƒÎ¼Î¿Ï…
                        link = None
                        try:
                            # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± ÎµÏÏÎµÏƒÎ·Ï‚ ÏƒÏ…Î½Î´Î­ÏƒÎ¼Î¿Ï… Î¼Î­ÏƒÏ‰ Î´Î¹Î±Ï†ÏŒÏÏ‰Î½ Î¼ÎµÎ¸ÏŒÎ´Ï‰Î½
                            a_elements = listing.find_elements(By.TAG_NAME, "a")
                            if a_elements:
                                for a in a_elements:
                                    href = a.get_attribute("href")
                                    if href and "marketplace/item" in href:
                                        link = href
                                        break
                        except Exception as e:
                            safe_print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÎµÎ¾Î±Î³Ï‰Î³Î®Ï‚ ÏƒÏ…Î½Î´Î­ÏƒÎ¼Î¿Ï…: {str(e)}")
                        
                        # Î•Î¾Î±Î³Ï‰Î³Î® ÎµÎ¹ÎºÏŒÎ½Î±Ï‚
                        image_url = None
                        try:
                            img_elements = listing.find_elements(By.TAG_NAME, "img")
                            if img_elements:
                                # Î ÏÎ¿Ï„Î¹Î¼Î¬Î¼Îµ data-src Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ (lazy loading)
                                src = img_elements[0].get_attribute("data-src")
                                if not src:
                                    src = img_elements[0].get_attribute("src")
                                    
                                if src:
                                    if src.startswith("//"):
                                        src = "https:" + src
                                    image_url = src
                        except Exception as e:
                            safe_print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÎµÎ¾Î±Î³Ï‰Î³Î®Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚: {str(e)}")
                        
                        # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î¿Ï‚ ÏƒÏ„Î· Î»Î¯ÏƒÏ„Î± Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î®Î´Î· ÎºÎ±Î¹ Î­Ï‡ÎµÎ¹ ÏŒÎ»Î± Ï„Î± Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î± ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±
                        if title and price and link and (not any(link == existing[2] for existing in facebook_products)):
                            with products_lock:
                                facebook_products.append((title, price, link, image_url))
                                safe_print(f"  âœ… Î ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎµ: {title} - {price}â‚¬")
                    
                    except Exception as e:
                        safe_print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Î±Î³Î³ÎµÎ»Î¯Î±Ï‚: {str(e)}")
                        continue
            
            except Exception as e:
                safe_print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÎµÏÏÎµÏƒÎ·Ï‚ Î±Î³Î³ÎµÎ»Î¹ÏÎ½: {str(e)}")
        
        # Î¤ÎµÎ»Î¹ÎºÎ® Î±Î½Î±Ï†Î¿ÏÎ¬
        safe_print(f"\nğŸ“Š Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ {len(facebook_products)} Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î± ÏƒÏ„Î¿ ÎµÏÏÎ¿Ï‚ Ï„Î¹Î¼Î®Ï‚ {min_price}â‚¬ - {max_price}â‚¬")
        for idx, (title, price, link, _) in enumerate(facebook_products, 1):
            safe_print(f"{idx}. {title} - {price}â‚¬ - {link}")
    
    except Exception as e:
        import traceback
        traceback.print_exc(file=sys.stderr)
        safe_print(f"âŒ ÎšÏÎ¯ÏƒÎ¹Î¼Î¿ ÏƒÏ†Î¬Î»Î¼Î±: {str(e)}")
    
    finally:
        try:
            driver.quit()
        except:
            pass
    
    return facebook_products

def search_vendora(search_term, min_price, max_price):
    global vendora_products
    vendora_products = []  # Reset for each search
    
    # Redirect stderr to handle encoding issues
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    
    options = webdriver.FirefoxOptions()
    options.add_argument('--headless')  # Enable headless mode
    options.add_argument('--disable-gpu')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--window-size=1920,1080')  # Larger window for headless mode
    options.set_preference("general.useragent.override", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.9999.99 Safari/537.36")
    
    # Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ ÏƒÎµÎ»Î¯Î´Î±Ï‚
    options.set_preference("network.cookie.cookieBehavior", 0)  # Accept all cookies
    options.set_preference("network.cookie.lifetimePolicy", 0)  # Keep cookies until expiration
    options.set_preference("privacy.cookies.cookieBehavior", 0)  # Accept all cookies
    options.set_preference("dom.disable_beforeunload", True)  # Disable pre-exit warnings
    options.set_preference("browser.tabs.disableBackgroundZombification", False)  # Speed up tab switching
    options.set_preference("network.http.pipelining", True)  # Enable HTTP pipelining
    options.set_preference("network.http.proxy.pipelining", True)
    options.set_preference("network.http.max-connections", 256)  # Increase max connections
    options.set_preference("network.http.max-connections-per-server", 32)

    driver = webdriver.Firefox(options=options)
    wait = WebDriverWait(driver, 2)  # ÎœÎµÎ¹Ï‰Î¼Î­Î½Î¿Ï‚ Ï‡ÏÏŒÎ½Î¿Ï‚ Î±Î½Î±Î¼Î¿Î½Î®Ï‚ Î³Î¹Î± Ï€Î¹Î¿ ÎµÏ€Î¹Î¸ÎµÏ„Î¹ÎºÎ® Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·

    try:
        # Direct search URL
        direct_url = f"https://vendora.gr/items?q={search_term.replace(' ', '+')}"
        driver.get(direct_url)
        safe_print(f"Navigating to URL: {direct_url}")
        time.sleep(3)  # ÎœÎµÎ¹Ï‰Î¼Î­Î½Î¿Ï‚ Ï‡ÏÏŒÎ½Î¿Ï‚ Î±Î½Î±Î¼Î¿Î½Î®Ï‚ Î±ÏÏ‡Î¹ÎºÎ®Ï‚ Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚

        # Scroll to load more results
        safe_print("Loading more results...")
        previous_product_count = 0
        max_attempts = 3  # ÎœÎµÎ¹ÏÏƒÎ±Î¼Îµ Ï„Î¿Î½ Î±ÏÎ¹Î¸Î¼ÏŒ Ï„Ï‰Î½ Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¹ÏÎ½ Î³Î¹Î± Ï„Î±Ï‡ÏÏ„ÎµÏÎ· ÎµÎºÏ„Î­Î»ÎµÏƒÎ·
        attempts = 0
        no_new_products_count = 0

        while attempts < max_attempts:
            # ÎœÎµÏ„ÏÎ®ÏƒÏ„Îµ Ï„Î¿Î½ Ï„ÏÎ­Ï‡Î¿Î½Ï„Î± Î±ÏÎ¹Î¸Î¼ÏŒ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½
            current_count = len(driver.find_elements(By.CSS_SELECTOR, 'a[href*="/items/"]'))
            safe_print(f"Current product count: {current_count}")
            
            # Î•Î¬Î½ Î´ÎµÎ½ Ï€ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎ±Î½ Î½Î­Î± Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î±, Î±Ï…Î¾Î®ÏƒÏ„Îµ Ï„Î¿Î½ Î¼ÎµÏ„ÏÎ·Ï„Î®
            if current_count == previous_product_count:
                no_new_products_count += 1
                if no_new_products_count >= 2:  # Î¤ÎµÏÎ¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚ Î¼ÎµÏ„Î¬ Î±Ï€ÏŒ 2 ÏƒÏ…Î½ÎµÏ‡ÏŒÎ¼ÎµÎ½ÎµÏ‚ Ï€ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹ÎµÏ‚ Ï‡Ï‰ÏÎ¯Ï‚ Î½Î­Î± Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î±
                    safe_print("No new products after multiple scrolls. Finished loading.")
                    break
            else:
                no_new_products_count = 0  # Î•Ï€Î±Î½Î±Ï†Î¿ÏÎ¬ Î¼ÎµÏ„ÏÎ·Ï„Î® Î±Î½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î½Î­Î± Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î±
            
            # Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏƒÏ„Îµ Ï„Î¿Î½ Ï„ÏÎ­Ï‡Î¿Î½Ï„Î± Î±ÏÎ¹Î¸Î¼ÏŒ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ Î³Î¹Î± ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·
            previous_product_count = current_count
            
            # Î Î¹Î¿ ÎµÏ€Î¹Î¸ÎµÏ„Î¹ÎºÏŒ scrolling Î³Î¹Î± Ï„Î±Ï‡ÏÏ„ÎµÏÎ· Ï†ÏŒÏÏ„Ï‰ÏƒÎ·
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.2);")
            time.sleep(0.3)
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.4);")
            time.sleep(0.3)
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.6);")
            time.sleep(0.3)
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.8);")
            time.sleep(0.3)
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.1)
            
            attempts += 1

        safe_print(f"Finished loading after {attempts} scroll attempts. Found {previous_product_count} potential product links.")
                
        # JavaScript to extract products with images - Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ Î³Î¹Î± Ï„Î±Ï‡ÏÏ„Î·Ï„Î±
        js_products = driver.execute_script("""
        const products = [];
        const productLinks = Array.from(document.querySelectorAll('a[href*="/items/"]'));
        const processedUrls = new Set();
        
        for (const link of productLinks) {
            if (!link.href || 
                link.href.includes('/user/items/') || 
                link.href.includes('/items/create') ||
                processedUrls.has(link.href)) continue;
            
            processedUrls.add(link.href);
            
            let title = link.textContent.trim() || link.querySelector('h2, h3, h4')?.textContent.trim() || link.href.split('/').pop().replace(/-/g, ' ');
            
            let priceText = '';
            const priceRegex = /(\\d+[.,]?\\d*)\\s*â‚¬|â‚¬\\s*(\\d+[.,]?\\d*)|\\b(\\d+[.,]?\\d*)\\s*ÎµÏ…ÏÏ\\b/i;
            
            // Optimized price search - look directly at link first, then one parent up
            const match = link.textContent.match(priceRegex);
            if (match) {
                priceText = match[0];
            } else if (link.parentElement) {
                const parentMatch = link.parentElement.textContent.match(priceRegex);
                if (parentMatch) priceText = parentMatch[0];
            }
            
            // Optimized image finding
            let imageUrl = null;
            const imgElement = link.querySelector('img') || link.parentElement?.querySelector('img');
            if (imgElement) {
                imageUrl = imgElement.src || imgElement.dataset.src;
            }
            
            products.push({
                title: title.substring(0, 200), // Limit title length
                price: priceText,
                link: link.href,
                imageUrl: imageUrl
            });
        }
        
        return products;
        """)

        # Process products extracted by JavaScript
        for product in js_products:
            try:
                title = product.get('title', '').strip()
                price_text = product.get('price', '').strip()
                link = product.get('link', '').strip()
                image_url = product.get('imageUrl', None)
                
                # Validate product link - Î±Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿Ï‚ Î­Î»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Ï„Î±Ï‡ÏÏ„Î·Ï„Î±
                if not link or '/items/' not in link:
                    continue
                
                # Extract price - Î²ÎµÎ»Ï„Î¹Ï‰Î¼Î­Î½Î· Î­ÎºÎ´Î¿ÏƒÎ· Î³Î¹Î± ÏƒÏ‰ÏƒÏ„Î® Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î´Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ Ï‡Î¹Î»Î¹Î¬Î´Ï‰Î½
                price = 0
                if price_text:
                    # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
                    clean_price_text = price_text.replace(' ', '').replace('â‚¬', '').replace('ÎµÏ…ÏÏ', '')
                    
                    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Î¼Î¿ÏÏ†Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼Îµ Ï„ÎµÎ»ÎµÎ¯Î± Ï‰Ï‚ Î´Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î¹ÎºÏŒ Ï‡Î¹Î»Î¹Î¬Î´Ï‰Î½ (Ï€.Ï‡. 1.500)
                    if '.' in clean_price_text and ',' not in clean_price_text:
                        # Î‘Ï†Î±Î¹ÏÎ¿ÏÎ¼Îµ Ï„Î¹Ï‚ Ï„ÎµÎ»ÎµÎ¯ÎµÏ‚ Ï€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Ï‡Î¹Î»Î¹Î¬Î´Ï‰Î½
                        price_str = clean_price_text.replace('.', '')
                    elif '.' in clean_price_text and ',' in clean_price_text:
                        # Î ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· 1.234,56
                        if clean_price_text.rindex('.') < clean_price_text.rindex(','):
                            price_str = clean_price_text.replace('.', '').replace(',', '.')
                        # Î ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· 1,234.56
                        else:
                            price_str = clean_price_text.replace(',', '')
                    elif ',' in clean_price_text:
                        # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÎºÏŒÎ¼Î¼Î±Ï„Î¿Ï‚ ÏƒÎµ Ï„ÎµÎ»ÎµÎ¯Î± Î³Î¹Î± Î´ÎµÎºÎ±Î´Î¹ÎºÎ¬
                        price_str = clean_price_text.replace(',', '.')
                    else:
                        # Î‘Ï€Î»ÏŒÏ‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ Ï‡Ï‰ÏÎ¯Ï‚ Î´Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬
                        price_str = clean_price_text
                    
                    try:
                        # Î•Î¾Î±Î³Ï‰Î³Î® Î¼ÏŒÎ½Î¿ Ï„Ï‰Î½ Î±ÏÎ¹Î¸Î¼ÏÎ½ ÎºÎ±Î¹ Ï„ÎµÎ»ÎµÎ¯Î±Ï‚ (Î´ÎµÎºÎ±Î´Î¹ÎºÎ¬) Î±Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î¬Î»Î»Î¿Î¹ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
                        price_match = re.search(r'(\d+\.?\d*)', price_str)
                        if price_match:
                            price = float(price_match.group(1))
                        else:
                            continue
                    except ValueError:
                        continue  # Î Î±ÏÎ±Î»ÎµÎ¯Ï€Î¿Ï…Î¼Îµ Î±Î½Ï„Î¯ Î½Î± ÎºÎ±Ï„Î±Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ ÏƒÏ†Î¬Î»Î¼Î± Î³Î¹Î± Ï„Î±Ï‡ÏÏ„Î·Ï„Î±
                
                # Î’ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ min_price ÎºÎ±Î¹ max_price ÎµÎ¯Î½Î±Î¹ float Ï€ÏÎ¹Î½ Ï„Î· ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·
                min_price_float = float(min_price) if min_price is not None else None
                max_price_float = float(max_price) if max_price is not None else None
                
                # Check if price is within the specified range
                if (min_price_float is None or max_price_float is None) or (min_price_float <= price <= max_price_float):
                    # Î Î±ÏÎ±Î»ÎµÎ¯Ï€Î¿Ï…Î¼Îµ Ï„Î¿Î½ Î­Î»ÎµÎ³Ï‡Î¿ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Ï‰Î½ Î³Î¹Î± Î±Ï€Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎºÎ±Î¹ Ï„Î±Ï‡ÏÏ„Î·Ï„Î±
                    # ÎºÎ±Î¸ÏÏ‚ Î­Ï‡Î¿Ï…Î¼Îµ Î®Î´Î· ÎµÎ»Î­Î³Î¾ÎµÎ¹ ÏƒÏ„Î¿ JavaScript Î¼Îµ Ï„Î¿ processedUrls Set
                    vendora_products.append((title, price, link, image_url))

            except Exception as e:
                # Î£Îµ Ï€Î±ÏÎ±Î³Ï‰Î³Î¹ÎºÏŒ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½ Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î±Ï†Î±Î¹ÏÎ­ÏƒÎµÏ„Îµ Ï„Î·Î½ ÎµÎºÏ„ÏÏ€Ï‰ÏƒÎ· Î³Î¹Î± Ï„Î±Ï‡ÏÏ„Î·Ï„Î±
                # safe_print(f"Î£Ï†Î¬Î»Î¼Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î¿Ï‚: {e}")
                continue

        # Print diagnostic information
        safe_print(f"Total products found: {len(vendora_products)}")

    except Exception as e:
        safe_print("Vendora search error")
    finally:
        driver.quit()
        



def search_sources(search_term, min_price, max_price, max_pages=1):
    """Search across multiple sources."""
    try:
        min_price = float(min_price)
        max_price = float(max_price)

        safe_print(f"Processing prices: {min_price} - {max_price}")
        
        # Î•ÎºÎºÎ¹Î½Î®ÏƒÏ„Îµ Ï„Î± threads
        skroutz_thread = threading.Thread(target=lambda: safe_thread_run(search_skroutz, search_term, min_price, max_price))
        vendora_thread = threading.Thread(target=lambda: safe_thread_run(search_vendora, search_term, min_price, max_price))
        facebook_thread = threading.Thread(target=lambda: safe_thread_run(search_facebook, search_term, min_price, max_price))

        skroutz_thread.start()
        vendora_thread.start()
        facebook_thread.start()

        skroutz_thread.join()
        vendora_thread.join()
        facebook_thread.join()

        # Pre-allocate list with estimated size for better performance
        estimated_size = len(skroutz_products) + len(vendora_products) + len(facebook_products)
        all_products = []
        all_products.reserve(estimated_size) if hasattr(all_products, 'reserve') else None  # Only in Python 3.12+

        # Streamlined filtering and conversion
        for source, products_list in [
            ("skroutz", skroutz_products), 
            ("vendora", vendora_products),
            ("facebook", facebook_products)
        ]:
            for product_data in products_list:
                title, price, link = product_data[0], product_data[1], product_data[2]
                image_url = product_data[3] if len(product_data) > 3 else None
                
                if price is not None and min_price <= price <= max_price:

                    all_products.append({
                        "title": title, 
                        "price": price, 
                        "link": link,
                        "source": source,
                        "imageUrl": image_url
                    })

        # Î§ÏÎ®ÏƒÎ· Ï„Î·Ï‚ TimSort (Ï…Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î·Ï‚ Python) Î¬Î¼ÎµÏƒÎ± Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·
        all_products.sort(key=lambda x: x['price'])
        
        safe_print(f"Original min_price: {min_price}")
        safe_print(f"Original max_price: {max_price}")
        try:
            converted_min = float(min_price)
            safe_print(f"Converted min_price: {converted_min}")
        except ValueError as e:
            safe_print(f"Failed to convert min_price: {e}")

        try:
            converted_max = float(max_price)
            safe_print(f"Converted max_price: {converted_max}")
        except ValueError as e:
            safe_print(f"Failed to convert max_price: {e}")
        
        return all_products

    except ValueError:
            safe_print(f"Error: Invalid prices provided. Please enter valid numbers for minimum and maximum prices.")
            return None, None

# Script execution
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
    try:
        if len(sys.argv) < 4:
            safe_print("âŒ Not enough arguments provided")
            print(json.dumps([]))
            sys.exit(0)
        
        search_term = sys.argv[1]
        min_price = sys.argv[2]
        max_price = sys.argv[3]
        
        max_pages = 1
        if len(sys.argv) >= 5:
            max_pages = sys.argv[4]
        
        results = search_sources(search_term, min_price, max_price, max_pages)
        
        # Î ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î± Î±Î½ ÎµÎ¯Î½Î±Î¹ None Î® Î¬Î´ÎµÎ¹Î¿
        if not results:
            results = []
        
        print(json.dumps(results, ensure_ascii=False))
        sys.exit(0)  # âœ… Î Î¬Î½Ï„Î± ÎµÏ€Î¹Ï„Ï…Ï‡Î¯Î± ÏŒÏ„Î±Î½ Ï†Ï„Î¬Î½ÎµÎ¹ ÎµÎ´Ï

    except Exception as e:
        error_details = {
            "error": str(e),
            "traceback": traceback.format_exc()
        }
        safe_print(f"âŒ Unhandled exception: {str(e)}")
        print(json.dumps([]))  # âœ… Î“Ï…ÏÎ½Î¬ÎµÎ¹ Î¬Î´ÎµÎ¹Î¿ array ÏƒÏ„Î¿ output, Î³Î¹Î± Î½Î± Î¼Î· ÏƒÏ€Î¬ÎµÎ¹ Ï„Î¿ API
        sys.exit(0)  # âœ… ÎŒÏ‡Î¹ Î±Ï€Î¿Ï„Ï…Ï‡Î¯Î±, exit 0
